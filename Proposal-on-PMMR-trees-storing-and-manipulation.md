## PMMR и эффективность, предложения

* 2 варианта храниения PMMR дерева: быстрый (1) и компактный (2). Вариант 1 - для узлов, которые способны выдавать куски истории в сеть, вариант 2 - для легких клиентов, кошельков и пр.
* Вариант 1 позволяет быстро находить объект по смещению в файле, 32*i, вариант 2 нуждается в дополнительном индексе i=>offset, который может храниться в любом kv-store
* Главный принцип: узлы заданной высоты хранятся в отдельных файлах (и стало быть в массивах, когда файл memory-mapped), таким образом, higher_index(parent) = i/2. Нахождение пути для заданного объекта и вытягивание части дерева для отправки в сеть в случае варианта хранения №1 будет очень быстрым, при №2 - просто быстрым. Отправится N-1 массивов (если дырки - разреженных массивов) + верхушка дерева.
* Pruning в 1-м варианте - обнуление листьев нижнего уровня, далее движемся вверх и обнуляем на верхних уровнях, где это можно. Также можно предложить алгоритм по удалению сразу M>1 листьев (у узла из высших уровней тогда будет еще 1 поле - сколько всего листьев по прежнему ссылается на его брата)
* Во 2-м варианте pruning сводится к удалению элементов из индекса и (время от времени) компактингу файлов с данными. Тут можно рассмотреть, не будет ли быстрее все узлы хранить в kv-storage, раз тут перформанс на 2-м плане. Понятно, что ключ это структура { node_height, index }, упаковать можно в uint64_t
* Можно рассмотреть хранение данных для 1-го варианта в чанках, тогда при полном занулении чанка №j можно и от файла избавиться.
* Ну и конечно, обратный индекс нужен где-то в kv-storage: hash => { data, index }
* Добавление хэша в дерево: добавляется хэш в массив нижнего уровня, апдейтятся или добавляются пэренты вплоть до верхушки, которые будут последними элементами следующего по высоте массива. Как преддусмотрено в Меркель-три, последний такой элемент может быть братом сам себе для расчета пэрента, ... т.е все остальное как и везде ...