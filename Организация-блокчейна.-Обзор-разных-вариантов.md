# Транзакции, блоки, блокчейн

Итак, мы рассмотрели транзакции в MimbleWimble. После формирования транзакции она отправляется в узел и в какой-то момент майнер формирует новый блок в котором эта транзакция становится *видимой*.
Блокчейн по сути является цепочкой (связанным списком) из блоков, в которой каждый новый блок ссылается на предыдущий (включая его хэш), таким образом что практически невозможно подделать блок в середине цепочки. С другой стороны формирование блока включает в себя PoW, таким образом чтобы практически невозможно было подделать длинную цепочку блоков (точнее - сделать это со скоростью превышающей "естественный" рост блокчейна).

Блок в MimbleWimble содержит описание всех входных и выходных UTXOs, и соответствующие ядра транзакций. Т.е. по сути является одной большой транзакцией. Более того, он является *канонической* транзакцией, в которой элементы каждого типа отсортированы, что во-первых "путает следы", а во-вторых - облегчает поиск. Валидация блока должна проверить следующее:

* Предыдущий блок на который данный блок ссылается - действительно существует, и имеет соответствующий хэш.
* Проверяются все входные UTXOs.
   * Они должны быть созданы в одном из предыдущих блоков
   * Они **не** должны быть потрачены в одном из блоков с момента создания и до текущего блока.
   * Их параметры позволяют их использовать в данном блоке. Например, имеют соответствующую зрелость (maturity) и т.п.
* Проверяются все выходные UTXOs на наличие правильной сигнатуры (rangeproof или др. сигнатура если это открытый UTXO).
* Проверяются все ядра транзакций на наличие правильной сигнатуры.
* Проверяется арифметика блока: сумма всех входов и сумма всех выходов равно сумме всях ядер плюс *offset* (его явная часть).
* Проверяется PoW, хэш блока, и пр. параметры

Из всего перечисленного самая нетривиальная часть - это проверка входных UTXO. Все остальные проверки - *локальные*, т.е. не требуют никакой информации помимо того что есть в блоке.
Сейчас мы рассмотрим варианты того как можно организовать блокчейн, и какие преимущества и недостатки у каждого варианта. При обзоре разных стратегий надо иметь ввиду следующие факторы:

### Не все участники системы *обязаны* делать валидацию блоков.
В завимисости от дизайна системы, валидация может требовать дополнительных ресурсов (напимер, большой объём локально хранимых данных), и в этом случае возможно существование *лёгких* клиентов, которые либо делают частичную верификацию, либо заинтересованы лишь в уведомлении о состоянии их транзакций и UTXOs. Это называется *SPV-клиент* - simplified payment verification.

### Что необходимо сделать новому клиенту прежде чем он сможет полноценно работать (cold start)
В самом простом варианте клиент должен полностью скачать весь блокчейн и провести полную верификацию. Разумеется это неоптимальный вариант, ведь клиенту неважна вся история транзакций, ему важно знать текущее состояние системы.

Одно из существенных преимуществ MimbleWimble в том что блоки можно объединять также как и транзакции, таким образом что потраченные UTXOs полностью удаляются. Это позволяет эффективно *компрессировать* историю блокчейна. Но при этом вопрос валидации скомпрессированного блокчейна усложняется. В ситуации с классическим блокчейном каждый созданный блок подразумевает PoW, и в консенсус выбирается цепочка с наибольшим суммарным PoW, таким образом предотвращая подделку целой цепочки. Но если предположить что блокчейн может сокращаться, то предположение о преимуществе наиболее длинной/трудоёмкой цепочки становится неверным, к тому же нелогично вкладывать новый PoW в компрессию существующих транзакций.

Таким образом в модели предполагающей консенсус на основе PoW скомпрессированный блокчейн не может полностью заменить исходный. Подробнее об этом позже.

### Уникальность UTXO
В грине и связанных с ним обсуждениях существует консенсус на тему того что нельзя допускать существование идентичных UTXOs (т.е. таких у которых и сумма и ключ совпадают). С другой стороны такой вариант всё-таки желательно поддерживать, т.к. он потенциально даёт дополнительные возможности (подробно об этом в главе о транзакциях).

# Наивный вариант

В самом простом варианте валидация входных UTXOs работает "дословно". Т.е. для того чтобы проверить факт существования входного UTXO и его параметры проверяющий сканирует цепочку блоков в обратном порядке, до тех пор пока данный UTXO не будет обнаружен. Точнее, мы ищем появления и траты данного UTXO, и так до тех пор пока кол-во рождений не превысит кол-во трат.

Преимущества:
* Это самый простой вариант, который не требует сохранения никаких данных кроме самих блоков
* Для указания входных UTXOs в блоке достаточно лишь сослаться на них (commitment, плюс, возможно, некоторые параметры), не нужны никакие громоздкие *доказательства*, раздувающие размер блока.
   * То же касается и транзакций которые отсылаются в узел.

Недостатки:
* Необходимо локально хранить всю историю блоков
   * Это автоматически лишает SPV клиенты возможности верификации.
* Алгоритм проверки входных UTXOs неэфективен. Зависит линейно от кол-ва блоков в цепочке (и логарифмически от размеров блоков).

Этот вариант нежизнеспособен, разумеется ввиду слишком неэфективной проверки входных UTXOs. Мы его приводим как базу для дальнейших рассуждений.

# Вариант с локальным отслеживанием всех непотраченных UTXOs
В этом варианте предполагается что пользователь локально хранит информацию о всех непотраченных UTXOs. Будем называть это *снапшотом*. Получая новый блок снапшот используется для валидации входных UTXOs, затем он обновляется: из него удаляются потраченные UTXOs, и вместо них добавляются новые (выходные).

Снапшот можно хранить в бинарном дереве, отсортированном по тому же принципу что и в блоке. Это позволит эфективные модификации: если обозначить кол-во существующих UTXOs N, а кол-во модификаций M, то получаем:

* Для небольших изменений (M << N): O(M * log(N))
* Для больших изменений: O(M + N), используя что-то вроде одного прохода merge-sort

В качестве готовой имплементации вполне можно взять DB с одним индексом (sqlite & friends), по сути это и будет то что надо.

Заметим также что обработка блока с модификацией снапшота полностью обратима. Т.е. если в какой-то момент решается перейти на другую ветку, то можно эфективно "отмотать" снапшот к началу новой ветки, и затем обработать блоки с этой точки.
Заметим также что необходимо хранить лишь минимальную информацию об UTXOs. К слову нет смысла хранить rangeproofs.

Преимущества:
* Сохраняем компактный протокол транзакций и блоков (т.е. минимальные ссылки на входные UTXOs).
* Историю блоков локально хранить необязательно. Достаточно хранить лишь "хвост", для того чтобы в случае со сменой цепочки консенсуса была возможность перейти на новую ветку.

Недостатки:
* Необходимо хранить полный снапшот всех непотраченных UTXOs. Это меньше чем полные блоки, но всё-таки может быть слишком много для SPV клиентов.
* Для построения снапшота необходимо обработать всю историю блоков (т.е. хранить необязательно, но обработать надо).

Этот вариант уже является вполне жизнеспособным. Майнеры и полноценные клиенты обязаны работать с полным снапшотом, но SPV клиенты не имеют возможности верификации.

# Разделяем блоки и заголовки, решаем проблему cold start.
Как мы уже говорили, в MimbleWimble есть возможность объединения блоков, так чтобы получить скомпрессированный вариант истории транзакций, и даже вся история вполне может быть описана одним блоком. Вопрос в том как убедить клиента что этот блок действительно отображает текущее состояние системы.

Это можно решить таким образом. Вводим понятие *заголовка блока*. Заголовок блока должен включать в себя ссылку на предыдущий заголовок, а также компактные данные которые однозначно привязаны к <u>текущему состоянию системы</u>, т.е. все непотраченные UTXOs, ядра транзакций и т.д. Что именно за данные - увидим позже, для простоты предположим что это просто хэш. Далее, PoW высчитывается не на содержимое блока, и <u>только на заголовок</u>.

### Как майнер создаёт новый блок
* Выбираем и проверяем транзакции, которые должны войти в блок.
* Высчитываем хэш нового состояния системы (подразумевается состояние после обработки этого блока)
* Формируем заголовок блока, включающий этот хэш и привязку к предыдущему заголовку
* Высчитываем PoW для заголовка

Новосозданный блок включает в себя следующее:
* Заголовок блока, привязанный к предыдущему, включающий в себя хэш состояния системы и PoW.
* Тело блока, которое привязано с заголовку, и содержит списки входных/выходных UTXOs, ядра транзакций и т.д.

### Что делает новый клиент
Прежде всего скачивает и проверяет всю историю заголовков. Заголовки имеют небольшой фиксированный размер.

Валидация заголовков включает в себя:
* Проверка целостности цепочки (т.е. верность ссылок вплоть до заголовка генезис-блока)
* Проверка PoW каждого заголовка

Заметим что это не является полноценной валидацией всей системы, т.к. по хэшам состояния системы (которые есть в заголовках) невозможно судить о верности этого состояния (т.е. то что эти хэши действительно описывают возможные состояния системы). Но при этом очевидно что данная цепочка подразумевает суммарный PoW который легко вычислить (т.е. мы не знаем легальна ли эта цепочка, но мы знаем что на её создание потрачены значительные ресурсы).

Затем клиент запрашивает скомпрессированную историю системы (один или несколько блоков). Эти блоки верифицируются и  интерпретируются. Клиент высчитывает хэш состояния системы согласно скомпрессированной истории, и сверяется с тем что должно быть судя по истории заголовков.

Если всё сходится, то мы делаем следующие выводы:
* Текущее состояние системы возможно, т.к. оно описано правильным набором транзакций.
* Создание этого состояния системы потребовало известного PoW.

На основании этих факторов, и с учётом того что нет цепочки с бОльшим PoW, клиент убеждается в верности текущего состояния системы.

Заметим что описание текущего состояния системы просто при помощи хэша подразумевает алгоритм линейно зависящий от размера системы, т.е. после каждого блока (который может включать в себя лишь немного транзакций) пересчёт такого хэша неоптимален. На практике используется другой подход. Какой именно - увидим позже.

# Дерево Меркла, как это сделано в биткоине

В биткоине при создании блока высчитывается дерево Меркла содержащее все выходные транзакции (только этого блока), и хэш корня этого дерева вписывается в заголовок. Заметим что это не имеет отношения к тому о чём мы говорили в прошлой главе, т.к. список всех выходов текущего блока не является полным описанием системы.

SPV клиенты скачивают лишь заголовки блоков. Затем если им нужно подтвердить создание определённого UTXO в определённом блоке, то они посылают соответствующий запрос полноценном клиенту. Если UTXO действительно создан в этом блоке, то полноценный клиент посылает путь Меркла (Merkle proof) на этот UTXO.

Таким образом SPV клиент может отслеживать когда интересующие его транзакции появляются в консенсусе без надобности скачивать целые блоки. Заметим следующее:
* Здесь нет верификации системы. Получая заголовки блоков SPV клиент видит что они являются частью блокчейна на который затрачен PoW, но у него нет возможности проверить что этот блокчейн легальный, т.е. содержит правильные транзакции.
   * Однако учитывая что на создание этого блокчейна тратятся ресурсы можно предположить что майнер не будет их тратить на заведомо неверный блокчейн, который не будет принят полноценными клиентами.
   * На всякий случай SPV клиент должен получать информацию от разных узлов
* Можно получить подтверждение создания UTXO в соответствующем блоке, но нет возможности проверить что этот UTXO не был потрачен в одном из следующих блоков
   * Таким образом логичное разумное применение этого протокола в том чтобы клиент мог увидеть когда его транзакции становятся видимыми. Это не подходит для верификации чужих UTXOs, т.к. не даёт защиты от double-spending.

# Кодирование состояния системы при помощи дерева Меркла (PMMR & friends)
Здесь мы рассмотрим эфективные схемы кодирования состояния системы, которое необходимо, в частности, для cold start.

## Что вообще можно делать с деревом Меркла
Предположим что существует множество объектов закодированных в дереве Меркла. Причём составитель дерева знает пути ко всем объектам, а проверяющий знает исключительно хэш корня.

### Верификация
Это классический вариант. Проверяющий получает описание элемента и путь Меркла. Он высчитывает хэш элемента, после чего итеративно эмулирует путь, и в конце он должен получить известный ему хэш корня.

### Удаление элемента
То же что и верификация, но предполагается что после верификации элемент надо *удалить*. Причём под удалением мы предполагаем что удаление этого элемента из дерева повлияет на некоторыэ хэши, включая хэш корня дерева. Таким образом видимым результатом удаления является <u>пересчёт хэша корня дерева</u>.

После *удаления* элемента уже будет невозможно доказать его существование в дереве, т.е. верификация пути Меркла для этого элемента не пройдёт. В этом и заключается суть удаления.

### Добавление элемента
Тот же принцип, но в данном случае элемент надо добавить. Проверяющий сперва предполагает что данного элемента в дереве нет, и эмулирует путь к корню, чтобы убедиться что он получает текущий известный ему хэш. Затем процедура повторяется уже с учётом добавления нового элемента, и таким образом мы получаем новый хэш. Опять таки, видимым результатом удаления является <u>пересчёт хэша корня дерева</u>.

Заметим что модификации дерева, т.е. удаление и добавление, изменяют путь Меркла к другим элементам, путь к которым проходит через модифицируемые узлы. Т.е. модификации приводят к изменению описания пути к другим элементам.

## Эфективное кодирование состояния системы в заголовке блока

Итак, как мы уже сказали, необходимо найти эфективный способ кодирования состояния системы в заголовке блока. Обычный хэш на каноническое состояние неэфективен, т.к. при создании каждого нового блока его придётся пересчитывать "с нуля".

Используем для этого дерево Меркла. Мы знаем что каждый блок "съедает" существующие UTXOs, генерирует новые, а также создаёт новые ядра транзакций. Всё это является объектами, которые можно хэшировать и закодировать в дереве (или в нескольких деревьях). Кроме того, как мы знаем, при модификациях дерева Меркла не надо его полностью пересчитывать, есть эфективный способ пересчёта изменяемых узлов, включая корень.

### Что именно кодируется

В самом простом варианте объекты кодируются полностью, и всё это хранится в одном дереве. Причём кодировка должна быть полной, чтобы потом клиент, получая скомпрессированную историю блокчейна, мог убедиться что каждый объект в системе был создан именно в таком виде и не было модифицирован.

В частности это означает:
* Кодировка UTXO включает в себя следующее:
   * Commitment
   * Rangeproof (или другую сигнатуру если он "открытый")
   * Пр. параметры (например, номер блока в котором он был создан чтобы знать его зрелость, является ли он coinbase и т.д.)
* Кодировка ядра транзакции включает следующее:
   * Закодированный остаток (`k*G`)
   * Сообщение `M` (может включать в себя *fee*, минимальный номер блока, и любое дополнительное сообщение)
   * Сигнатура

При синхронизации клиент получает полный список этих объектов в полном виде, а также точное описание того как они формируют дерево Меркла. Т.е. не отдельный путь Меркла к каждому объекту, а полную иерархию всех объектов в дереве. Это имеет следующие преимущества:
* Помимо доказательства присутстсвия перечисленных объектов это также доказаывает что ничего не скрыто.
* Более компактное кодирование.
* Минимальный размер заголовка блока (1 хэш на всё)

### Какие у этого варианта ограничения, и каковы альтернативы

Вышеописанный вариант идеально подходит для случая когда всю предыдущую историю можно переслать одним блоком. Но, зависимо от имплементации, на практике может быть удобно пересылать историю не одним блоком, а некоторым набором.

Дело в том что создание блоков компрессированной истории - процесс достаточно трудоёмкий, зависит линейно от кол-ва непотраченных UTXOs, а также линейно от кол-ва транзакций (т.к. ядра транзакций не исчезают). Поэтому по мере роста истории создание таких блоков в произвольных точках - может стать слишком дорогим удовольствием.

Можно имплементировать *логарифмическое* компрессирование по принципу каскада. Т.е. формирование цепочки блоков кодирующих диапазоны истории, так что в начале каскада блоки кодируют большие диапазоны, затем всё меньше. По мере накопления блоков они объединяются по принципу "снежного кома". Таким образом формируется кол-во блоков пропорциональное логарифму кол-ва оригинальных блоков.

В ситуации когда история передаётся несколькими блоками лишь первый может полностью кодировать всё дерево Меркла. Остальные должны кодировать изменения. Т.е. для каждого нового выходного параметра надо кодировать его полный путь в дереве, а входные параметры клиент должен удалять из дерева.

Впрочем, возможно это и излишне в обозримом будущем.

## Как полный клиент это имплементирует

Полный клиент должен держать полный снапшот, т.е. всю информацию о текущем состоянии системы. Непотраченные UTXOs должны храниться в индексированном виде с логарифмическим поиском (бинарное дерево с авто-балансировкой, или просто DB).
Помимо этого клиент должен хранить все объекты в дереве Меркла, а для UTXOs должны быть кросс-ссылки между деревом Меркла и деревом поиска UTXOs.

Обрабатывая (или создавая) новый блок клиент модифицирует дерево Меркла, и эфективно пересчитывает хэши. Причём то в каком виде и порядке новые элементы добавляются в дерево - детерминистическим способом оговорено в алгоритме, так что все клиенты одинаково интерпретируют блоки и выстраивают одно дерево, таким образом чтобы в блок не надо было записывать пути Меркла.

Эфективный способ заполнения дерева - стремление к *идеальному* дереву. При удалении элементов в дереве остаются "дырки", при этом мы не делаем специальных перестроек (т.н. ротаций) для баланскировки дерева. Вместо этого мы при добавлении элементов в дерево всегда заполняем все "дырки" прежде чем увеличить высоту дерева.

# Отличия от Грина

В грине также имплементирована идея блокчейна заголовков, которые доказывают PoW и уникально описывают состояние системы. Отличия следующие:

* Значительные отличия в организации дерева Меркла
   * Грин использует 3 (4?) дерева, нам достаточно одного, что уменьшает размер заголовка блока
   * Грин использует т.н. PMMR-вариант дерева. В нём из дерева никогда ничего не удаляется, вместо этого "дырки" помечаются как *NULL*, и заполнение дерева в любом случае идёт без связи с удалениями. Вместо этого можно эфективно заполнять "дырки" новыми данными, что немного экономит высоту дерева
* Отличия в описаниях UTXOs в транзакциях
   * Грин в качестве входного UTXO передаёт хэш блока в котором он был создан а также его путь Меркла (непонятно зачем).
   * В нашем дизайне достаточно лишь commitment. Или, как вариант, commitment + пр. параметры (номер блока и т.д.)
   * Грин не допускает существования UTXOs с идентичными commitments, а нам это никак не мешает, и даёт дополнительные возможности.
      * Однако в случае указания входного UTXO, возможно, стОит добавить уточняющие параметры, чтобы майнер правильно выбрал (например, его зрелость).
* Поддержка SPV клиентов.
   * В грине (АФАИК) клиент может лишь узнать зашёл ли данный UTXO в данный блок, и получить на него подтверждающий путь Меркла.
   * Мы можем это сделать без указания блока. Т.е. SPV клиент запрашивает информацию по UTXO, на что полноценный клиент может эфективно выдать список всех UTXOs, для каждого - его параметры (например, в каком блоке он появился), и путь Меркла в последнем блоке.
   * Мы также можем поддержать запросы по наличию ядра транзакции в блокчейне, что доказывает факт транзакции. Может пригодиться для подвтерждения транзакции с подписанным ядром содержащим сообщение, которое можно использовать для разбирательств.
      * Чтобы обработкат такого запроса была эфективной, и работал за логарифмическое время, это потребует определённого увеличения объёма локальных данных (чтобы имплементировать индекс).

# Другие варианты дизайна

Описанный дизайн подразумевает существование двух типов клиентов:
* Полноценный клиент
   * Полностью верифицирует блокчейн.
   * Имеет возможность хранения большого объёма данных.
   * Имеет адевкватный сетевой канал, чтобы получать новые блоки по мере их поступления.
   * Может также заниматься майнингом при наличии большого ресурса CPU. Если же речь только о валидации, то высокий ресурс CPU не нужен.

* SPV клиент
   * ограничен в хранении данных, CPU и сетевом трафике.
   * не участвует в верификации блокчейна.
   * заинтересован лишь в отслеживании состояния некоторых транзакций.

Есть также вариант клиента SPV-плюс. Его свойства:

   * ограничен в хранении данных и CPU, но при этом имеет адекватную скорость сети.
   * Участвует в верификации блокчейна, но не может заниматься майнингом.

Такой клиент будет получать блоки и верифицировать их. Однако для этого ему понадобится дополнительная информация: путь Меркла для каждого объекта блока (подноценному клиенту это не нужно).
